---
title: Operating Systems：Three Easy Piece笔记
categories: 操作系统
---



# Operating Systems：Three Easy Piece笔记

Operating Systems：Three Easy Pieces电子书地址https://pages.cs.wisc.edu/~remzi/OSTEP/

这本书从操作系统的3个部分：

- 虚拟化（virtualization）
- 并发（concurrency）
- 持久性（persistence）

操作系统实际上做了：

它取得 CPU、内存或磁盘等物理资源 （resources），甚对它们进行虚拟化（virtualize）。

它处理与甚发（concurrency）有关的麻烦 且棘手的问题。

它持久地（persistently）存储文件，从而使它们长期安全。

<!--more-->

## 第一部分 虚拟化

假设一个计算机只有一个CPU（尽管现代计算机一般拥有2个、4个或者更多CPU），虚拟 化要做的就是将这个CPU虚拟成多个虚拟CPU并分给每一个进程使用因此此，每个应用都 以为自己在独占CPU，但实际上只有一个CPU。这样操作系统就创造了美丽的假象——它 虚拟化了CPU。

### 第4章 进程

- 进程（Process）的非正式定义：就是运行中的程序
- 时分共享（time sharing）CPU技术：通过让一个进程只运行一个时间片，然后切换到其他进程，操作系统提供了存在多个虚拟CPU的假象。

将磁盘中的程序加载到内存中：

![4-1.png](OSTEP笔记/4-1.png)

- 所有现代操作系统都以某种形式提供以下API。
    - 创建（create）进程
    - 销毁（destroy）进程
    - 等待（wait）进程
    - 其他控制（miscellaneous control），例如让线程暂停一段时间
    - 状态（status），通常也有一些接口可以获得有关进程的状态信息

- 操作系统运行程序要做的事：

    - 操作系统运行程序必须做的第一件事是将代码和所有静态数据加载到内存中的进程的地址空间上。
    - 操作系统还需要为栈（C程序使用栈存放局部变量、函数参数和返回地址）分配内存，也可能为堆分配内存
    - 操作系统还将执行一些其他的初始化任务，特别是与输入/输出（I/O）相关的任务。
    - 最后启动程序， 即main()作为程序的入口。通过跳转到main()，OS将CPU的控制权转移到新创建的进程中，从而程序开始执行。

- 进程可以处于以下三种状态之一：

    - 运行（running）：进程正在处理器上运行。
    - 就绪（ready）：在就绪状态下，进程已准备好运行，但由于某种原因，操作系统选择不在此时运行。
    - 阻塞（blocked）：在阻塞状态下，一个进程执行了某种操作，直到发生其他事件 时才会准备运行。

    ```mermaid
    stateDiagram-v2
        运行 --> 就绪: 取消调度
        运行 --> 阻塞: I/O：发起
        就绪 --> 运行: 调度
        阻塞 --> 就绪: I/O：完成
        
    ```

    从就绪到运行意味着该进程已经被调度（scheduled）。从运行转移到就绪意味着该进程已经取消调度（descheduled）。一旦进程被阻塞（例如，通过发起I/O操作），OS将保持进程的这种状态，直到发生某种事件（例如，I/O完成）。此时，进程再次转入就绪状态（也可能立即再次运行，如果操作系统这样决定）

- 操作系统可能会为所有就绪的进程保留某种进程列表（process list），以及跟踪当前正在运行的进程的一些附加信息。

作业：

### 第5章 进程API

头文件[unistd.h](https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/unistd.h.html)

- 系统调用（System Call），以下函数包含在该头文件中

    - fork()：创建一个子进程

    - wait()：等待其他线程执行结束

    - exec()：将当前运行的程序替换为不同的运行程序，没有创建新的进程，exec()有几种变体：execl()、execle()、execlp()、execv()和 execvp()
    - kill()：向进程发送信号(signal)，包括要求进程睡眠、终止或其他有用的指令
- 调用fork()函数的例子：[p1.c](https://github.com/remzi-arpacidusseau/ostep-code/blob/master/cpu-api/p1.c)
- 调用wait()函数的例子：p2.c
- 调用exec()函数的例子：

### 第6章 机制：受限直接执行
> CPU虚拟化的基本思想：运行一个进程一段时间，然后运行另一个进程，如此轮换。通过以这种方式时分共享（time sharing）CPU，就实现了虚拟化。

构建这样的虚拟化机制存在一些问题：
- 第一个是性能：如何在不增加系统开销的情况下实现虚拟化？
- 第二个是控制权：如何有效地运行进程，同时保留对 CPU 的控制？
 
 CPU 虚拟化的关键底层机制，并将其统称为受限直接执行 （limited direct execution）。基本思路很简单：就让你想运行的程序在CPU上运行，但首先确保设置好硬件，以便在没有操作系统帮助的情况下限制进程可以执行的操作。

==解决性能问题：采用受限制的操作==
- 如何高效、可控地虚拟化CPU？
    - 为了使程序尽可能快地运行，操作系统开发人员想出了一种技术——我们称之为受限的直接执行（limited direct execution，LDE）：直接在CPU上运行程序即可
- 硬件通过提供不同的执行模式来协助操作系统。
    - CPU用户模式（user mode）：在用户模式下运行的代码会受到限制。例如，在用户模式下运行时，进程不能发出I/O请求。
    - CPU内核模式（kernel mode）：操作系统（或内核）就以这种模式运行。 在此模式下，运行的代码可以做它喜欢的事，包括特权操作，如发出I/O请求和执行所有类 型的受限指令。
- 如果用户希望执行某种特权操作（如从磁盘读取），可以执行系统调用。要执行系统调用，程序必须执行特殊的陷阱（trap）指令。该指令同时跳入内核并将特权级别提升到内核模式。完成后，操作系统调用一个特殊的从陷阱返回 （return-from-trap）指令，同时将特权级别降低，回到用户模式。

==操作系统重获CPU的控制权：==

- 协作方式：过去某些系统采用的一种方式（例如，早期版本的 Macintosh 操作系统或旧的Xerox Alto 系统）称为协作（cooperative）方式。操作系统相信系统的进程会合理运行。运行时间过长的进程被假定会定期放弃 CPU，以便操作系统可以决定运行其他任务。
- 非协作方式：操作系统进行控制
    - 在非协作方式下，可以利用时钟中断（timer interrput）重新获得CPU的控制权
> 进程以非协作的方式运行，添加时钟中断（timer interrupt）也让操作系统能够在 CPU 上重新运行。因此，该硬件功能对于帮助操作系统维持机器的控制权至关重要。
- 保存和恢复上下文：是继续运行当前正在运行的进程，还是切换到另一个进程。这个决定是由调度程序（scheduler）做出的，它是操作系统的一部分。决定进行切换，OS就会执行一些底层代码，即所谓的上下文切换（context switch）

CPU虚拟化化的关键底层机制，将其称为受限直接执行（limited direct execution，LDE）。基本思路：就让你想运行的程序在CPU上运行，但首先确保设置好硬件，以便在没有操作系统帮助的情况下限制进程可以执行的操作。

**一个LDE协议的例子：**
![6-1.png](OSTEP笔记/6-1.png)

### 第7章 进程调度
机制（mechanism）和策略（policy）的区别
- 机制：提供并实现确定的功能，比如运行进程的底层机制（如上下文切换）
- 策略：如何使用这些功能


调度指标：

- 周转时间（turnaround time）：$T_{周转时间}=T_{完成时间}-T_{到达时间}$
- 响应时间（response time）：$T_{响应时间} = T_{首次运行}−T_{到达时间}$

调度策略：

- 先进先出（First In First Out或FIFO）调度：先到达的任务先执行。
- 最短任务优先（Shortest Job First，SJF）调度：先运行最短的任务，然后是次短的任务，如此下去
- 最短完成时间优先（Shortest Time-to-Completion First，STCF）调度：向SJF添加抢占，称为最短完成时间优。每当新工作进入系统时，它就会确定剩余工作和新工作中， 谁的剩余时间最少，然后调度该工作。
- 轮转（Round-Robin， RR）调度：RR在一个时间片（time slice，有时称为调度量子，scheduling  quantum）内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直到结束。它反复执行，直到所有任务完成。

几种调度策略的图示：

![7-1.png](OSTEP笔记/7-1.png)

![7-2.png](OSTEP笔记/7-2.png)

- 重叠（overlap）操作可以最大限度地提高系统的利用率。比如，一个进程在等另一个进程的I/O完成时使用CPU，系统因此得到更好的利用。调度程序与I/O结合，对于STCF调度策略来说，图7.9可以很好地利用资源。将任务A看成5个10ms的子任务，任务A的第一个子任务完成后，发生I/O，此时CPU去处理任务B，等到任务A的第二个子任务到达。根据STCF策略，A的子任务2抢占B的CPU使用权并运行10ms，一个进程在等待另一个进程的I/O完成时使用CPU，系统因此得到更好的利用

![7-3.png](OSTEP笔记/7-3.png)

- 介绍了调度的基本思想，并开发了两类方法。==第一类是运行最短的工作，从而优化周转时间。第二类是交替运行所有工作，从而优化响应时间。但很难做到“鱼与熊掌兼得”，这是系统中常见的、固有的折中。==

### 第8章 多级反馈队列

- 著名的调度方法：多级反馈队列（Multi-level Feedback Queue， MLFQ）。多级反馈队列需要解决两方面的问题。首先，它要优化周转时间。其次，需要降低响应时间（MLFQ希望给用户很好的交互体验）。
- 饥饿（starvation）问题：如果系统有“太多”交互型工作，就会不断占用 CPU，导致长工作永远无法得到CPU（它们饿死了）
- 愚弄调度程序（game the scheduler）：用一些卑鄙的手段欺骗调度程序，让它给你远超公平的资源。进程在时间片用完之前，调用一个I/O操作（比如访问一个无关的文件），从而主动释放CPU。如此便可以保持在高优先级，占用更多的CPU时间。做得好时（比如，每 运行99%的时间片时间就主动放弃一次CPU），工作可以几乎独占CPU。 
- 优化后的MLFQ规则：
    - 规则1：如果A的优先级 > B的优先级，运行A（不运行B）。  
    - 规则2：如果A的优先级 = B的优先级，轮转运行A和B。 
    - 规则3：工作进入系统时，放在最高优先级（最上层队列）。  
    - 规则4：为了解决愚弄问题，一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次 CPU），就降低其优先级（移入低一级队列）。 
    - 规则5：为了避免挨饿问题，经过一段时间S，就将系统中所有工作重新加入最高优先级队列。 
- 大多数的MLFQ变体都支持不同队列可变的时间片长度。高优先级队列通常只有较短的时间片（比如 10ms 或者更少），因而这一层的交互工作可以更快地切换。相反，低优先级队列中更多的是 CPU 密集型工作，配置更长的时间片会取得更好的效果。

### 第9章  比例份额

- 调度程序——比例份额（proportional-share）调度程序，有时也称为公平份额（fair-share）调度程序。比例份额算法基于一个简单的想法：调度程序的最终目标，是确保每个工作获得一定比例的CPU时间，而不是优化周转时间和响应时间。
- 比例份额的两种实现：彩票调度和步长调度。但由于一些原因，并没有作为CPU调度程序被广泛使用。一 个原因是这两种方式都不能很好地适合 I/O

### 第10章 多处理器调度

### 第12章 关于内存虚拟化的对话
- 用户程序生成的每个地址都是虚拟地址（every address generated by a user program is a virtual address）。操作系统只是为每个进程提供一个假象，具体来说，就是它拥有自己的大量私有内存。在一些硬件帮助下，操作系统会将这些假的虚拟地址变成真实的物理地址，从而能够找到想要的信息。

### 第13章 地址空间

- 内存虚拟化：用户程序生成的每个地址都是虚拟地址。操作系统只是为每个进程提供一个假象，具体来说，就是它拥有自己的大量私有内存。在一些硬件帮助下，操作系统会将这些假的虚拟地址变成真实的物理地址，从而能够找到想要的信息。
- 操作系统需要提供一个易用 （easy to use）的物理内存抽象。这个抽象叫作地址空间（address space），是运行的程序看到的系统中的内存。
- 地址空间的例子如下，假设只有这3个部分：代码、栈和堆。当我们描述地址空间时，所描述的是操作系统提供给运行程序的抽象（abstract）。 程序不在物理地址0～16KB的内存中，而是加载在任意的物理地址。

![13-1.png](OSTEP笔记/13-1.png)

- 虚拟内存（VM）系统的目标
    - 透明（transparency）：程序不应该感知到内存被虚拟化的事实，相反，程序的行为就好像它拥有自己的私有物理内存。在幕后，操作系统（和硬件）完成了所有的工作，让不同的工作复用内存，从而实现这个假象。
    - 效率（efficiency）：效率体现在时间上（即不会使程序运行得更慢）和空间上（即不需要太多额外的内存来支持虚拟化）。在实现高效率虚拟化时，操作系统将不得不依靠硬件支持，包括TLB（第19章会介绍）这样的硬件功能。
    - 保护（protection）：操作系统应确保进程受到保护（protect）， 不会受其他进程影响，操作系统本身也不会受进程影响。保护让我们能够在进程之间提供隔离（isolation）的特性，每个进程都应该在自己的独立环境中运行，避免其他出错或恶意进程的影响。

- 小结
    - 这一章介绍了操作系统的一个重要子系统：虚拟内存。虚拟内存系统负责为程序提供一个巨大的、稀疏的、私有的地址空间的假象，其中保存了程序的所有指令和数据。操作系统在专门硬件的帮助下，通过每一个虚拟内存的索引，将其转换为物理地址，物理内存根据获得的物理地址但获取所需的信息。操作系统会同时对许多进程执行此操作，并且确保程序之间互相不会受到影响，也不会影响操作系统。


### 第14章 内存操作API 

- 在运行一个C程序的时候，会分配两种类型的内存。
    - 第一种称为栈内存，它的申请和释放操作是编译器来隐式管理的，所以有时也称为自动（automatic）内存。
    - 第二种称为堆（heap）内存，其中所有的申请和释放操作都由程序员显式地完成。

- 内存分配API
    - malloc()：传入要申请的堆空间的大小，它成功就返回一个指向新申请空间的指针，失败就返回NULL
    - realloc()：创建一个新的更大的内存区域，将旧区域复制到其中，并返回新区域的指针。
    - calloc()：分配内存，并在返回之前将其置零
    - free()：释放malloc()函数所分配的堆空间
- malloc()和free()不是系统调用，而是库调用。malloc库管理虚拟地址空间内的空间，但是它本身是建立在一些系统调用之上的，这些系统调用会进入操作系统，来请求本多内存或者将一 些内容释放回系统。

**为什么在你的进程退出时没有内存泄露？**
> 系统中实际存在两级内存管理。
>- 第一级是由操作系统执行的内存管理，操作系统在进程运行时将内存交给进程，并在进程退出（或以其他方式结束）时将其回收。
> - 第二级管理在每个进程中，例如在调用 malloc()和 free()时，在堆内管理。即使你没有调用 free()（并因此泄露了堆中的内存），操作系统也会在程序结束运行时，收回进程的所有内存（包括用于代码、栈，以及相关堆的内存页）。
> 
> 因此，对于短时间运行的程序，泄露内存通常不会导致任何操作问题

### 第15章 地址转换

- 地址转换（address translation）：硬件对每次内存访问进行处理（即指令获取、数据读取或写入），将指令中的虚拟（virtual）地址转换为数据实际存储的物理（physical）地址。

- 动态重定位（dynamic relocation）：基于硬件。每个CPU需要两个硬件寄存器：基址（base）寄存器和界限（bound）寄存器，有时称为限制（limit）寄存器。

    - 基址寄存器：存放物理地址的首地址
    - 界限寄存器：界限寄存器提供了访问保护，例如进程拥有4KB大小的地址空间，这个寄存器的值就是4KB

- 动态重定位具体原理：操作系统决定将某个进程加载到32KB的内存地址，因此将基址寄存器设置为这个值。于是有`物理地址=虚拟地址+基地址`。进程中使用的内存引用都是虚拟地址（virtual address），硬件接下来将虚拟地址加上基址寄存器中的内容，得到物理地址（physical address），再发给内存系统。 由于这种重定位是在运行时发生的，而且我们甚至可以在进程开始运行后改变其地址空间，这种技术一般被称为动态重定位（dynamic relocation）
- 内存管理单元：有时我们将CPU的这个负责地址转换的部分统称为内存管理单元（Memory Management Unit，MMU）。

转换示例：假设一个进程拥有4KB大小地址空间，它被加载到从16KB开始的物理内存中。转换结果如下表

| 虚拟地址 |      |           物理地址            |
| :------: | :--: | :---------------------------: |
|    0     |  →   |             16KB              |
|   1KB    |  →   |             17KB              |
|   3000   |  →   |             19384             |
|   4400   |  →   | 错误（越界），进程大小只有4KB |

- 为了支持动态重定位，硬件添加了新的功能，操作系统也必须提供相应的支持

动态重定位：操作系统的职责

| 操作系统的要求 | 解释                                                         |
| -------------- | ------------------------------------------------------------ |
| 内存管理       | 需要为新进程分配内存<br />从终止的进程回收内存  <br />一般通过空闲列表（free list）来管理内存 |
| 基址/界限管理  | 必须在上下文切换时正确设置基址/界限寄存器                    |
| 异常处理       | 当异常发生时执行的代码，可能的动作是终止犯错的进程           |

### 第16章  分段 

- 如果我们将整个地址空间放入物理内存，那么栈和堆之间的空间并没有被进程使用，却依然占用了实际的物理内存。因此，简单的通过基址寄存器和界限寄存器实现的虚拟内存很浪费。为了解决这个问题，分段（segmentation）的概念应运而生。

![16-1.png](OSTEP笔记/16-1.png)

- 分段将可分为代码段、堆段、栈段。硬件在地址转换时使用段寄存器，由于栈的地址是从大到小变化，段寄存器需要知道段的增长方向（用一位区分，比如1代表自小而大增长，0反之）。对于地址空间可能存在共享，比如代码段的共享，还需要硬件的支持，这就是保护位（protection bit）。物理内存中存放段，如下表所示

|  段  | 基址 | 大小 | 是否反向增长 |  保护   |
| :--: | :--: | :--: | :----------: | :-----: |
| 代码 | 32KB | 2KB  |      1       | 读-执行 |
|  堆  | 34KB | 2KB  |      1       |  读-写  |
|  栈  | 28KB | 2KB  |      0       |  读-写  |

如上图所示，该例子共有三个段，因此需要两位二进制数来表示。虚拟地址使用二进制形式的前两位表示使用哪个段（假设00表示代码段，01表示堆段，11表示栈段），后面的二进制数位表示段内的偏移量。偏移量与基址寄存器相加，硬件就得到了最终的物理地址。偏移量也简化了对段边界的判断。我们只要检查偏移量是否小于界限， 大于界限的为非法地址。

举个例子，假设访问虚拟地址15KB（上图中栈所在的虚拟地址），该虚拟地址的二进制形式是：11 1100 0000 0000（十六进制0x3C00）。硬件利用前两位（11）来指定栈段，段内偏移量为3KB。由于栈地址是反向增长的，必须从3KB中减去最大的段地址（假设是4KB），因此正确的偏移量是3KB减去4KB，即−1KB。 只要用这个反向偏移量（−1KB）加上基址（28KB），就得到了正确的物理地址 27KB，实现了从虚拟地址15KB到物理地址27KB的转换。

### 第17章 空闲空间管理

- 如果要管理的空闲空间由大小不同的单元构成，管理就变得困难。这种情况出现在用户级的内存分配库（如malloc()和free()），或者操作系统用分段（segmentation） 的方式实现虚拟内存。

**底层机制**
- 内部碎片（internal fragmentation）：已经分配的内存单元内部有未使用的空间（即碎片），造成了浪费。
- 外部碎片（external fragmentation）： 空闲空间被分割成不同大小的小块，成为碎片，后续的请求可能失败，因为没有一块足够大的连续空闲空间，即使这时总的空闲空间超出了请求的大小。 
- 内存分配程序的底层机制
    - 分割：它找到一块可以满足请求的空闲空间，将其分割，第一块返回给用户，第二块留在空闲列表中。
    - 合并：在归还一块空闲内存时，仔细查看要归还的内存块的地址以及邻它的空闲空间块。如果新归还的空间与一个原有空闲块相邻（或两个，就像这个例子），就将它们合并为一个较大的空闲块。

举个例子：
假设有30字节的堆，其对应的空闲列表如下所示，空闲列表中记录了空闲地址的起始地址和大小
![17-3.png](OSTEP笔记/17-3.png)
1. 如果申请大于10字节的内存会失败，这是因为两块空闲空间的大小都是10字节。
2. 如果申请1个字节的内存，分配程序会执行分割（splitting）：它找到一块可以满足请求的空闲空间，将其分割，第一块返回给用户，第二块留在空闲列表中
3. 合并（coalescing）：在归还一块空闲内存时，仔细查看要归还的内存块的地址以及邻它的空闲空间块。如果新归还的空间与一个原有空闲块相邻（或两个，就像这个例子），就将它们合并为一个较大的空闲块

**追踪已分配空间的大小**
free()函数所需参数只是一个指针，分配程序是怎么知道需要释放多大空间的内存？在使用`malloc()`函数分配时，大多数分配程序都会在头块（header）中保存一点额外的信息（比如内存块的大小）。假设使用`malloc(20)`分配20字节的空间

```c
//简化后的头块
typedef struct header_t {
    int size; 
    int magic; //库可以很容易地确定magic是否符合预期的值，作为正常性检查
} header_t;

//free函数通过指针运算得到头块的位置
void free(void *ptr) { 
    header_t *hptr = (void *)ptr - sizeof(header_t); 
} 
```
![17-1.png](OSTEP笔记/17-1.png)

**嵌入空闲列表**
到目前为止，我们这个简单的空闲列表还只是一个概念上的存在，它就是一个列表，描述了堆中的空闲内存块。但如何在空闲内存自己内部建立这样一个列表呢？以下是一个节点描述：
```c
typedef struct node_t{
    int size;
    struct node_t *next;
}node_t
```

空闲列表：描述了堆中的空闲内存块的列表
如何在空闲内存自己内部建立这样一个空闲列表？假设一个4KB的堆构建在某块空闲空间上，这块空间通过系统调用 mmap()获得。
```c
// mmap() returns a pointer to a chunk of free space 
node_t *head = mmap(NULL, 4096, PROT_READ|PROT_WRITE, 
    MAP_ANON|MAP_PRIVATE, -1, 0); 
head->size = 4096 - sizeof(node_t); 
head->next = NULL; 
```
一个空闲空间的例子：
最初空闲列表只有一个条目：空闲内存大小为4088个字节，下一个空闲空间的头块的地址为NULL。用户使用malloc()分配到了100个字节（实际上是108个字节）的空间，指针ptr指向该地址。使用free()归还空间时，free()函数通过指针运算得到头块的位置，并将头块后的空间释放掉。遍历空闲列表，合并（merge）相邻块。完成之后，堆又成了一个整体。

![17-2.png](OSTEP笔记/17-2.png)

**基本策略**
- 最优匹配（best fit）：首先遍历整个空闲列表，找到和请求大小一样或更大的空闲块，然后返回这组候选者中最小的一块。
    - 优点：选择最接它用户请求大小的块，从而尽量避免空间浪费。
    - 缺点：简单的实现在遍历查找正确的空闲块时，要付出较高的性能代价。
- 最差匹配（worse fit）：它尝试找最大的空闲块，分割并满足用户需求后，将剩余的块（很大）加入空闲列表。
    - 优点：不是向最优匹配那样可能剩下很多难以利用的小块。
    - 缺点：需要遍历整个空闲列表。更糟糕的是，会导致过量的碎片，同时还有很高的开销。
- 首次匹配（first fit）：找到第一个足够大的块，将请求的空间返回给用户。
    - 优点：有速度优势（不需要遍历所有空闲块）
    - 缺点：会让空闲列表开头的部分有很多小块
- 下次匹配（next fit）：下次匹配算法与首次匹配相比多了一个指针，该指针指向上一次查找结束的位置。其想法是将对空闲空间的查找操作扩散到整个列表中去，避免对列表开头频繁的分割。这种策略的性能与首次匹配很接它，同样避免了遍历查找。

**其他策略**
- 分离空闲列表（segregated list）：如果某个应用程序经常申请一种（或几种）大小的内存空间，那就用一个独立的列表，只管理这样大小的对象。
- 二分伙伴分配程序（binary buddy allocator）：在这种系统中，空闲空间首先从概念上被看成大小为 2^N^ 的大空间。当有一个内存分配请求时，空闲空间被递归地一分为二，直到刚好可以满足请求的大小（再一分为二就无法满足）。

### 第18章 分页
操作系统有两种方法，来解决大多数空间管理问题。
- 第一种是将空间分割成不同长度的分片，就像虚拟内存管理中的分段。但是，将空间切成不同长度的分片以后，空间本身会碎片化（fragmented），随着时间推移，分配内存会变得比较困难
- 因此，值得考虑第二种方法：将空间分割成固定长度的分片。在虚拟内存中，我们称这种思想为分页。

页与页帧：
- 页（page）：将一个进程的地址空间分割成固定大小的单元，每个单元称为一页。
- 页帧（page frame）：把物理内存看成是定长槽块的阵列。

一个64字节的地址空间与该地址空间到物理内存的映射如下所示，假设每个页的大小为16字节，64字节的地址空间可分成4页。
![18-1.png](OSTEP笔记/18-1.png)

为了记录地址空间的每个虚拟页放在物理内存中的位置，操作系统通常为每个进程保存一个数据结构，称为页表（page table）。对于这个例子，页表中存在4个条目：（虚拟页 0→物理帧 3）、（VP 1→PF 7）、（VP 2→PF 5）和（VP 3→PF 2）。

**一个地址转换的例子**
为了转换（translate）该过程生成的虚拟地址，我们必须首先将它分成两个组件：虚拟页面号（virtual page number，VPN）和页内的偏移量（offset）。对于上面的例子，进程的虚拟地址空间是64字节，我们的虚拟地址总共需要 6 位（2^6^ = 64）。因为64字节的地址空间分成了4页，所以使用两位二进制数表示VPN，4位二进制数表示页内的偏移量。
![18-2.png](OSTEP笔记/18-2.png)
假设要转换的虚拟地址是21，将21变成二进制形式“010101”。其中VPN是“01”，偏移量是“0101”。通过虚拟页号，我们现在可以检索页表，找到虚拟页1所在的物理页面。在上面的例子中虚拟页1对应页帧7（物理帧号PFN是7），地址转换过程如下：

![18-3.png](OSTEP笔记/18-3.png)

**页表存在哪里？**
由于页表如此之大，我们没有在 MMU 中利用任何特殊的片上硬件，来存储当前正在运行的进程的页表，而是将每个进程的页表**存储在内存**中。

**页表中有什么？**
页表中的一个条目称为PTE。操作系统通过虚拟页号（VPN）检索该页表（对于线性页表本质上是数组），并在该索引处查找页表项（PTE），以便找到期望的物理帧号（PFN）。一个x86页表项的例子：
![18-4.png](OSTEP笔记/18-4.png)

- PFN：physical frame number，物理帧号
- P：存在位（present bit），表示该页是在物理存储器（physical memory）还是在磁盘（disk）上
- D：脏位（dirty bit），表明页面被带入内存后是否被修改过。
- R/W：读写位，确定是否允许写入该页面

页表过大会造成程序运行速度变慢，第19章的TLB是用来解决这个问题。

### 第19章 分页：快速地址转换（TLB）
> 使用分页作为核心机制来实现虚拟内存，可能会带来较高的性能开销。因为要使用分页，就要将内存地址空间切分成大量固定大小的单元（页），并且需要记录这些单元的地址映射信息。因为这些映射信息一般存储在物理内存中，所以在转换虚拟地址时，分页逻辑上需要一次额外的内存访问。每次指令获取、显式加载或保存，都要额外读一次内存以得到转换信息，这慢得无法接受。

**这一章需要解决分页第一个问题：如何加速地址转换。**
地址转换旁路缓冲存储器（translation-lookaside buffer，TLB），它就是频繁发生的虚拟到物理地址转换的硬件缓存（cache），TLB用于加速地址转换。TLB位于CPU内部的内存管理单元MMU。
![19-2.png](OSTEP笔记/19-2.png)

**示例：访问数组**
为了弄清楚 TLB 的操作，我们来看一个简单虚拟地址追踪，看看 TLB 如何提高它的性能。
```c
int sum = 0;
for(int i = 0; i < 10; i++){
    sum += a[i];
}
```
假设a[0]~a[9]的地址空间中的分布如下：
![19-3.png](OSTEP笔记/19-3.png)

1. 当访问第一个数组元素（a[0]）时，CPU 会看到载入虚存地址 100。硬件从中提取VPN（VPN=06），然后用它来检查 TLB，寻找有效的转换映射。假设这里是程序第一次访问该数组，结果是 TLB 未命中。
2. 接下来访问a[1]，此时TLB命中。因为数组的第二个元素在第一个元素之后，它们在同一页。因为我们之前访问数组的第一个元素时，已经访问了这一页，所以TLB中缓存了该页的转换映射。因此成功命中。访问 a[2]同样成功（再次命中），因为它和a[0]、a[1]位于同一页。
3. 依次类推，可得10次数组访问操作中TLB的行为表现：未命中、命中、命中、未命中、命中、命中、命中、未命中、命中、命中。

如果页大小变大一倍（32 字节，而不是 16），数组访问遇到的未命中更少。页的大小一般为 4KB， 这种情况下，密集的、基于数组的访问会实现极好的 TLB 性能，每页的访问只会遇到一次未命中。

- 类似其他缓存，TLB 的成功依赖于空间和时间局部性。硬件缓存背后的思想是利用指令和数据引用的局部性（locality）。
    - 时间局部性（temporal locality）：最近访问过的指令或数据项可能很快会再次访问
    - 空间局部性（spatial locality）：当程序访问内存地址x时，可能很快会访问邻近x的内存

**TLB的内容**
一条地址映射可能存在 TLB 中的任意位置，硬件会并行地查找 TLB，找到期望的转换映射。一条TLB项内容可能像这样：VPN ｜ PFN ｜ 其他位

**上下文切换时对 TLB 的处理**
有了 TLB，在进程间切换时（因此有地址空间切换），会面临一些新问题。具体来说，TLB 中包含的虚拟到物理的地址映射只对当前进程有效，对其他进程是没有意义的。上下文切换的时候清空 TLB，这是一个可行的解决方案。但是每次进程运行，当它访问数据和代码页时，都会触发 TLB 未命中。如果操作系统频繁地切换进程，这种开销会很高。为了减少这种开销，一些系统增加了硬件支持，实现跨上下文切换的 TLB 共享。比如地址空间标识符：
- 地址空间标识符（Address Space Identifier，ASID）,可以把ASID看作是进程标识符（Process Identifier，PID），但通常比PID位数少（PID一般32位，ASID一般是8位）

一个例子：MPIS R4000的TLB项
![19-1.png](OSTEP笔记/19-1.png)
- VPN：虚拟页号
- PFN：物理帧号
- G：全局位（Global），如果全局位置为1，就会忽略ASID
- ASID：地址空间标识符
- C：一致性位（Coherence，C），决定硬件如何缓存该页
- D：脏位（dirty），表示该页是否被写入新数据

### 第20章 分页：较小的表
**这一章需要解决分页第二个问题：页表（page table）太大，因此消耗的内存太多。**
**1. 简单的方法：使用更大的页**
假设一个 32 位地址空间（2^32^ 字节），4KB（2^12^字节）的页和一个 4 字节的页表项。一个地址空间中大约有一百万个虚拟页面（$\frac{2^{32}}{2^{12}}$）。乘以页表项4字节，得到页表大小为4MB（2^22^字节）。现在使用16KB（2^14^字节）的页面，虚拟地址中的偏移量是14位（2^14^B=16KB），VPN需要18位。现在线性页表中有2^18^个项，因此每个页表的总大小为 1MB，页表大小减少到原来的四分之一。
**缺点**：大内存页会导致每页内的浪费，这被称为内部碎片（internal fragmentation）问题（因为浪费在分配单元内部）。因此，大多数系统在常见的情况下使用相对较小的页大小：4KB（如 x86）或 8KB（如 SPARCv9）。

**2. 混合方法：分页和分段**
杂合方法不是为进程的整个地址空间提供单个页表，而是为每个逻辑分段提供一个。
采用混合方法的虚拟地址如下所示：
![20-1.png](OSTEP笔记/20-1.png)

Seg部分使用两位表示使用的哪个段：假设 00 是未使用的段，01 是代码段，10 是堆段，11 是栈段。
> 杂合方案的关键区别在于，每个分段都有界限寄存器，每个界限寄存器保存了段中最大有效页的值。例如，如果代码段使用它的前 3 个页（0、1 和 2），则代码段页表将只有 3个项分配给它，并且界限寄存器将被设置为 3。内存访问超出段的末尾将产生一个异常，并可能导致进程终止。以这种方式，与线性页表相比，杂合方法实现了显著的内存节省。栈和堆之间未分配的页不再占用页表中的空间（仅将其标记为无效）

**3. 多级列表**
如何去掉页表中的所有无效区域，而不是将它们全部保留在内存中？采用多级列表（multi-level page table）。
> 注：PFN是指Physical Frame Number（物理帧号）或Page Frame Number（页帧号）

![20-4.png](OSTEP笔记/20-5.png)

多级列表的例子：

![20-2.png](OSTEP笔记/20-2.png)
在这个例子中，虚拟页0和1用于代码，虚拟页4和5用于堆，虚拟页254和虚拟页255用于栈。共有256个页，假设页表项PTE的大小是4字节，那么页表的大小为1KB（256×4），1KB的页表可表示为可以分为16个64字节的页。这个例子中一页是64字节，可容纳16个PTE。16KB的地址空间需要14位二进制数来表示，该14位的虚拟地址结构如下：
![20-3.png](OSTEP笔记/20-3.png)

页目录需要为页表的每页提供一个项，共有16页，因此页面目录索引需要4位VPN来索引，要找到这个PTE，我们必须使用VPN的剩余位索引到页表的部分。

![20-4.png](OSTEP笔记/20-4.png)
假设要查找VPN为254的第0个字节，该虚拟地址为`11 1111 1000 0000`，前四位1111是页目录索引号，即页表目录的第15个条目（从0开始），对应的PDE中的PFN是101，并且有效位是1，表示物理页101有效；第二次查找从页101所在的页表中查找，下四位1110是页表索引，即对应页表中的第14个条目，得到物理页号55；剩下的位数都是表示偏移量，偏移量为0。
可计算出物理地址：`PhysAddr =（PTE.PFN << SHIFT）+ offset = 00 1101 1100 0000 = 0x0DC0`

---

**多级列表例子，使用paging-multilevel-translate.py文件**

这个例子中需要注意：
1. 页面大小是32字节
2. 32KB的虚拟地址空间
3. 物理内存有128个页帧（物理页），共4KB的物理内存（128×32B）

按一页32字节排列的内存块如下所示：
```sh
page 0: 08 00 01 15 11 1d 1d 1c 01 17 15 14 16 1b 13 0b ...
page 1: 19 05 1e 13 02 16 1e 0c 15 09 06 16 00 19 10 03 ...
page 2: 1d 07 11 1b 12 05 07 1e 09 1a 18 17 16 18 1a 01 ...
...
page 33: 7f 7f 7f 7f 7f 7f 7f 7f b5 7f 9d 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f f6 b1 7f 7f 7f 7f
...
page 86: 7f 7f 7f 7f 7f 7f 7f c5 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f 7f ca 7f 7f ee 7f 7f 7f 7f 7f 7f 7f 7f
...
page 108: 83 fe e0 da 7f d4 7f eb be 9e d5 ad e4 ac 90 d6 92 d8 c1 f8 9f e1 ed e9 a1 e8 c7 c2 a9 d1 db ff
...
page 127: ...
```
并且规定PTE的格式如下，VALID表示有效位（1表示有效，0表示无效），PF6~PF0表示物理帧号
```sh
VALID | PFN6 ... PFN0
```
PDE的格式如下，VALID表示有效位（1表示有效，0表示无效），PT6~PT0表示页表号
```sh
VALID | PT6 ... PT0
```


>注：
虚拟地址需要15位，10位用作VPN，5位用作页内偏移量。PDE Index需要占用VPN中的高5位，PTE Index需要占用VPN中的低5位，因为一页最多可容纳32个1字节的PTE。
物理地址需要12位，7位用作PFN，5位用作偏移量。



1.虚拟地址0x611c转换为对应的物理地址
0x611c转为15位二进制数`110 0001 0001 1100`，其中高5位11100（0x18）表示页目录索引（PDE Index），中间5位01000（0x08）表示页表项索引（PTE Index），最后5位表示页内偏移量0x1C。由于PDBR = 108（Page Direction Base Register，页目录基址寄存器），那么需要从第108页（PFN=108）中去查找PDE，根据PDE Index=0x18（24）可获得对应的值是0xa1（有效1，PFN 0X21[十进制33]）。由于PDE中的有效位是1，则表示PFN=33的页表有效。使用PFN=33，去查找对应的PTE。PTE索引是0x08，获得对应的值是0xb5（有效1，PFN 0X35[十进制53]）。于是12位物理地址由7位PFN（0x35）和5位偏移量（0x1C），可得物理地址0x6bc，可得其中的值0x08。
答案：虚拟地址0x611c --> 物理地址0x6bc，该地址中的值是0x08。

可得如下的结果：
```sh
Virtual Address 0x611c:
  --> pde index:0x18 [decimal 24] pde contents:0xa1 (valid 1, pfn 0x21 [decimal 33])
    --> pte index:0x8 [decimal 8] pte contents:0xb5 (valid 1, pfn 0x35 [decimal 53])
      --> Translates to Physical Address 0x6bc --> Value: 0x08
```
2.虚拟地址0x3da8转换为对应的物理地址
0x3da8转为15位二进制数`011 1101 1010 1000`，其中高5位01111（0x0f）表示页目录索引（PDE Index），中间5位011010（0x1a）表示页表项索引（PTE Index），最后5位表示页内偏移量0x08。同样从PFN=108去查找PDE，根据PDE Index=0x0f可得0xd6（有效位1，PFN 0x56），有效位为1表示该条PDE有效，将从PFN=0x56（86）的内存中去查找。根据PTE Index=0x1a可得PTE的内容为0x7f（有效位0，PFN 0x7f），有效位是0，表示该条PTE无效。

最终结果如下：

```sh
Virtual Address 0x3da8:
  --> pde index:0xf [decimal 15] pde contents:0xd6 (valid 1, pfn 0x56 [decimal 86])
    --> pte index:0xd [decimal 13] pte contents:0x7f (valid 0, pfn 0x7f [decimal 127])
      --> Fault (page table entry not valid)
```

### 第21章 超越物理内存：机制
我们需要支持许多同时运行的巨大地址空间。到目前为止，我们一直假设所有页都常驻在物理内存中。但是，为了支持更大的地址空间，操作系统需要把当前没有使用的那部分地址空间找个地方存储起来。在现代系统中，硬盘（hard disk drive）通常能够满足这个需求。因此，在我们的存储层级结构中，大而慢的硬盘位于底层，内存之上。

**交换空间**
交换空间（switch space）：在硬盘上开辟一部分空间用于物理页的移入和移出，在操作系统中，一般这样的空间称为交换空间。一个4页的物理内存和一个8页的交换空间的例子：
![20-1.png](OSTEP笔记/21-1.png)
3个进程（Proc0、Proc1、Proc2）只有一部分有效页被加载到内存中了，还有一部分存在于交换空间中未被使用。进程3（Proc3）在交换空间中未被加载到物理内存中。

**存在位**
在页表项中添加一条信息：存在位（present bit）。如果存在位设置为1，则表示该页存在于物理内存中；如果存在位设置为0，则页不在内存中，而在硬盘上。访问不在物理内存中的页，这种行为通常被称为页错误（page fault）。

**小结**
> 访问超出物理内存大小的时候，要做到这一点，在页表结构中需要添加额外信息，比如增加一个存在位（present bit，或者其他类似机制），告诉我们页是不是在内存中。如果不存在，则操作系统页错误处理程序（page-fault handler）会运行以处理页错误（page fault），从而将需要的页从硬盘读取到内存，可能需要先换出内存中的一些页，为即将换入的页腾出空间。

###  第22章 超越物理内存：策略
由于内存压力（memory pressure）迫使操作系统换出（paging out）一些页，为常用的页腾出空间。确定要踢出（evict）哪个页（或哪些页）封装在操作系统的替换策略（replacement policy）中。

这章介绍了如下替换策略：
- 最优替换策略：踢出最远将来才会问访问的页。很难实现，因为某一页未来是否被访问是未知的。
- FIFO：先进先出策略。发生替换时，队列尾部的页（“先入”页）被踢出。
- 随机：随机踢出页。
- 最少最近使用（Least-Recently-Used，LRU）：优先踢出最近最少使用的页。
> 随着系统中页数量的增长，扫描所有页的时间字段只是为了找到最精确最少使用的页，这个代价太昂贵。想象一下一台拥有 4GB 内存的机器，内存切成 4KB 的页。这台机器有一百万页，即使以现代 CPU 速度找到 LRU 页也将需要很长时间。。这就引出了一个问题：我们是否真的需要找到绝对最旧的页来替换？找到差不多最旧的页可以吗? 可以使用时钟算法来是实现LRU。

- 时钟算法（clock algorithm）：操作系统使用该算法来近似LRU，以减少计算开销。

> 近似LRU这个想法需要硬件增加一个使用位（use bit，有时称为引用位，reference bit）。系统的每个页有一个使用位，然后这些使用位存储在某个地方（例如，它们可能在每个进程的页表中，或者只在某个数组中）。每当页被引用（即读或写）时，硬件将使用位设置为 1。但是，硬件不会清除该位（即将其设置为 0），这由操作系统负责。

> 时钟算法：有一个简单的方法称作时钟算法（clock algorithm）[C69]。想象一下，系统中的所有页都放在一个循环列表中。时钟指针（clock hand）开始时指向某个特定的页（哪个页不重要）。当必须进行页替换时，操作系统检查当前指向的页 P 的使用位是 1 还是 0。如果是 1，则意味着页面 P 最近被使用，因此不适合被替换。然后，P 的使用位设置为 0，时钟指针递增到下一页（P + 1）。该算法一直持续到找到一个使用位为 0 的页，使用位为 0 意味着这个页最近没有被使用过（在最坏的情况下，所有的页都已经被使用了，那么就将所有页的使用位都设置为 0）。

假设最多缓存3页，页访问序列是0,1,2,1,3,0,3,1,2,1。几种策略示例：
**最优策略**
```sh
ARG addresses 0,1,2,1,3,0,3,1,2,1
ARG addressfile
ARG numaddrs 10
ARG policy OPT
ARG clockbits 2
ARG cachesize 3
ARG maxpage 10
ARG seed 0
ARG notrace False

Solving...

Access: 0  MISS Left  ->          [0] <- Right Replaced:- [Hits:0 Misses:1]
Access: 1  MISS Left  ->       [0, 1] <- Right Replaced:- [Hits:0 Misses:2]
Access: 2  MISS Left  ->    [0, 1, 2] <- Right Replaced:- [Hits:0 Misses:3]
Access: 1  HIT  Left  ->    [0, 1, 2] <- Right Replaced:- [Hits:1 Misses:3]
Access: 3  MISS Left  ->    [0, 1, 3] <- Right Replaced:2 [Hits:1 Misses:4]
Access: 0  HIT  Left  ->    [0, 1, 3] <- Right Replaced:- [Hits:2 Misses:4]
Access: 3  HIT  Left  ->    [0, 1, 3] <- Right Replaced:- [Hits:3 Misses:4]
Access: 1  HIT  Left  ->    [0, 1, 3] <- Right Replaced:- [Hits:4 Misses:4]
Access: 2  MISS Left  ->    [0, 1, 2] <- Right Replaced:3 [Hits:4 Misses:5]
Access: 1  HIT  Left  ->    [0, 1, 2] <- Right Replaced:- [Hits:5 Misses:5]

FINALSTATS hits 5   misses 5   hitrate 50.00

```

**FIFO策略**
```sh
ARG addresses 0,1,2,1,3,0,3,1,2,1
ARG addressfile
ARG numaddrs 10
ARG policy FIFO
ARG clockbits 2
ARG cachesize 3
ARG maxpage 10
ARG seed 0
ARG notrace False

Solving...

Access: 0  MISS FirstIn ->          [0] <- Lastin  Replaced:- [Hits:0 Misses:1]
Access: 1  MISS FirstIn ->       [0, 1] <- Lastin  Replaced:- [Hits:0 Misses:2]
Access: 2  MISS FirstIn ->    [0, 1, 2] <- Lastin  Replaced:- [Hits:0 Misses:3]
Access: 1  HIT  FirstIn ->    [0, 1, 2] <- Lastin  Replaced:- [Hits:1 Misses:3]
Access: 3  MISS FirstIn ->    [1, 2, 3] <- Lastin  Replaced:0 [Hits:1 Misses:4]
Access: 0  MISS FirstIn ->    [2, 3, 0] <- Lastin  Replaced:1 [Hits:1 Misses:5]
Access: 3  HIT  FirstIn ->    [2, 3, 0] <- Lastin  Replaced:- [Hits:2 Misses:5]
Access: 1  MISS FirstIn ->    [3, 0, 1] <- Lastin  Replaced:2 [Hits:2 Misses:6]
Access: 2  MISS FirstIn ->    [0, 1, 2] <- Lastin  Replaced:3 [Hits:2 Misses:7]
Access: 1  HIT  FirstIn ->    [0, 1, 2] <- Lastin  Replaced:- [Hits:3 Misses:7]

FINALSTATS hits 3   misses 7   hitrate 30.00

```

**LRU策略**
```sh
ARG addresses 0,1,2,1,3,0,3,1,2,1
ARG addressfile
ARG numaddrs 10
ARG policy LRU
ARG clockbits 2
ARG cachesize 3
ARG maxpage 10
ARG seed 0
ARG notrace False

Solving...

Access: 0  MISS LRU ->          [0] <- MRU Replaced:- [Hits:0 Misses:1]
Access: 1  MISS LRU ->       [0, 1] <- MRU Replaced:- [Hits:0 Misses:2]
Access: 2  MISS LRU ->    [0, 1, 2] <- MRU Replaced:- [Hits:0 Misses:3]
Access: 1  HIT  LRU ->    [0, 2, 1] <- MRU Replaced:- [Hits:1 Misses:3]
Access: 3  MISS LRU ->    [2, 1, 3] <- MRU Replaced:0 [Hits:1 Misses:4]
Access: 0  MISS LRU ->    [1, 3, 0] <- MRU Replaced:2 [Hits:1 Misses:5]
Access: 3  HIT  LRU ->    [1, 0, 3] <- MRU Replaced:- [Hits:2 Misses:5]
Access: 1  HIT  LRU ->    [0, 3, 1] <- MRU Replaced:- [Hits:3 Misses:5]
Access: 2  MISS LRU ->    [3, 1, 2] <- MRU Replaced:0 [Hits:3 Misses:6]
Access: 1  HIT  LRU ->    [3, 2, 1] <- MRU Replaced:- [Hits:4 Misses:6]

FINALSTATS hits 4   misses 6   hitrate 40.00
```

**近似LRU策略：时钟算法**
```sh
ARG addresses 0,1,2,1,3,0,3,1,2,1
ARG addressfile
ARG numaddrs 10
ARG policy CLOCK
ARG clockbits 2
ARG cachesize 3
ARG maxpage 10
ARG seed 0
ARG notrace False

Solving...

Access: 0  MISS Left  ->          [0] <- Right Replaced:- [Hits:0 Misses:1]
Access: 1  MISS Left  ->       [0, 1] <- Right Replaced:- [Hits:0 Misses:2]
Access: 2  MISS Left  ->    [0, 1, 2] <- Right Replaced:- [Hits:0 Misses:3]
Access: 1  HIT  Left  ->    [0, 1, 2] <- Right Replaced:- [Hits:1 Misses:3]
Access: 3  MISS Left  ->    [0, 1, 3] <- Right Replaced:2 [Hits:1 Misses:4]
Access: 0  HIT  Left  ->    [0, 1, 3] <- Right Replaced:- [Hits:2 Misses:4]
Access: 3  HIT  Left  ->    [0, 1, 3] <- Right Replaced:- [Hits:3 Misses:4]
Access: 1  HIT  Left  ->    [0, 1, 3] <- Right Replaced:- [Hits:4 Misses:4]
Access: 2  MISS Left  ->    [0, 3, 2] <- Right Replaced:1 [Hits:4 Misses:5]
Access: 1  MISS Left  ->    [0, 3, 1] <- Right Replaced:2 [Hits:4 Misses:6]

FINALSTATS hits 4   misses 6   hitrate 40.00
```

**小结**
在许多情况下，由于内存访问和磁盘访问时间之间的差异增加，这些算法的重要性降低了。由于分页到硬盘非常昂贵，因此频繁分页的成本太高。所以，过度分页的最佳解决方案往往很简单：购买更多的内存。




## 第二部分 并发



[Linux C API参考手册](https://wizardforcel.gitbooks.io/linux-c-api-ref/content/index.html)